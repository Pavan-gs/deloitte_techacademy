
OLTP --> Databases (transaction) --> row oriented file format
OLAP --> Data warehouse (analytics) --> column oriented file format

Cloud Service Providers
=======================
MS Azure, AWS, GCP, Oracle, Bluehost

Infrastructure As A Service (IAAS) --> Servers, Virtual Machines, Virtual network

Software As A Service --> Ready to use software/apps that are hosted on cloud [Gmail,CRM,ERP, Office 365]

Platform As A Service --> Provides a platform to build, test and deploy apps (Azure app service, Google playstore) 

Networking As A Service --> AWS direct connect, AZ networking

ID As A Service --> SOS, Multi factor authentication, (AZ Active Directory[Entra ID], AWS IAM)

Deployment Models
=================
Public cloud --> Shared by multiple Organisations 
Private cloud --> Private to a Organisation/individual
Hybrid cloud --> Combination of private and public cloud
Multi-cloud --> Combination of services from different cloud providers (vm-->azure, Storage-->aws, analytics-->gcp)
Community cloud --> Shared infrastructure with multiple organisations with similar needs

Az regions --> Physical location where data centers are set-up
Availability zones --> Physically seperate your resources within an Az region

Services
========

1. Compute Services --> Virtual machines, App service, AKS, Functions

2. Networking --> Vnet, Load balancer, VPN gateway, DNS

3. Storage --> Blob, Files, Disk, Queue & table

4. Management --> 

4. Database --> SQL, Cosmos, Mysql/postgresql

5. Security --> AAD (Entra ID), Key-vault, Defender

6. AI & Analytics --> ML, Synapse, Cognitive servics, Vision, OpenAI, ADF

7. Devops --> CI/CD pipelines, code repo, agile tools, monitor, application insights

Virtual Machines
================

VM is a virtual computer with hardware/software etc.

Isolation
Internet communication
Traffic filtering
on-premise connectivity

Availability sets --> To ensure high availability & fault tolerance
Distribute VM's across mutliple fault domains and update domains

Scale sets --> Auto scale up-down of resources

Key based authentication --> Pair of cryptographic keys
Public --> shared with server, private --> it's kept on your local laptop

Authentication
Authorization

Protocol for inbound
windows --> RDP
Linux --> SSH
To access from web --> http, https

sudo apt update
sudo apt install apache2 -y

OSI layers
==========
Application layer --> Human -- computer interaction --> az portal
Presentation layer --> Ensures that the data is in a usable format and is where the data encryption  --> ssl, tls encryption
Session layer --> Maintains the connections and is responsible for controlling the ports and sessions --> maintaining ssh/rdp session to an azure vm
Transport --> Transmits the data using tracsaction protocols TCP and UDP --> TCP, UDP
Network --> Decides which physical path the data follows --> Vnet
Data link --> Defines the format of data on the network --> Ethernet/Vlan
Physical --> Transmits the raw bit of the data streams over physical medium --> actual servers/switches/cables

Socket --> IP + Port
HTTP --> 80
SSH --> 22
HTTPs --> 443

Azure bastion --> Used to SSH/connect to your VM without a public IP address --> Paid service

Virtual network
===============

Azure Vnet
==========
Acts as a Communication channel between the resources launched in the cloud, it is a representation of your own network in the cloud,
logical isolation of azure cloud dedicated to your subscription 

SDN --> Hypervisors enforce virtual isolation --> logical layer on physical h/w
traffic is encapsulated using vxlan/vt-x

Subnet --> A Sub network
Route tables --> To control the flow of network traffic within a virtual network
Network Security Group --> Firewall, responsible for filtering incoming, outgoing traffic from/to your VM
Network Interface Card --> Enable communication between VM's over a network
DNS
End-points

IP Addresses
============
Internet protocol --> Unique numerical address

Public --> Globally unique, accessible from the internet 
Private --> Local network, not accessible from internet
Static IP --> Manually assigned, remains constant
Dynamic IP --> Automatically assigned, changes periodically

IPV4 (32 bit) --> 4 decimal numbers --> ranging between 0 and 255 (192.168.1.0) --> 2**32 --> 
IPV6 (128 bit) --> 2**128

-,-,-,-

0-255,0-255,0-255,0-255

0.0.0.0 - 255.255.255.255

10.164.40.77

CIDR --> Classless Inter Domain Routing
=======================================
192.168.0.0 to 192.168.0.255 = 256 unique addresses --> 192.168.0.0/24
192.168.0.0, 192.168.0.1, 192.168.0.2, 192.168.0.3 ..........192.168.0.255 

192.170.0.0/16 --> 192.170.0.0--192.170.255.255 --> 256*256 unique addresses --> 65,536
192.170.0.1 -- 192.170.0.255
192.170.1.0--> 192.170.255.255

192.0.0.0/8 --> 256*256*256

Lab 1
=====
Creating VNet

1. Create a Virtual Network (ip range --> 10.0.0.0/16-->65536 ip)
2. Let's have two subnets, 1 for Web servers (10.0.1.0/24), 
and another one for DB servers (10.0.2.0/24)
3. Create and configure NSG --> public nsg(public subnet) --> allow inbound(http,https,ssh), 
private nsg(private subnet) --> allow inbound(sql, (10.0.1.0/24), ssh((10.0.1.0/24))

DNS set-up
option 1 --> under vm, networking, configdns label(pvn-demo) and then access
http://pvn-demo.eastus.cloudapp.azure.com/

option 2 --> buy a domain from registrar

Security
Security Center (Defender cloud) --> JIT (Just in time)
Key vault --> Secret, Keys, Certificates management, storing secrets with Hardware Security Model (HSM) 
Sentinel --> To detect and respond to threats
Active directory (Entra id)
Policy
Dedicated Hosts --> Private servers for compliance

Network Security Groups --> Firewall, filter inbound & outbound traffic
Application Security Group --> Grouping of servers with similar ports, functions like web servers

Az CLI, POWERSHELL, CLOUD SHELL
===============================
1. creating resource group --> az group create --name networkingdemoRG --location eastus
2. creating vnet --> az network vnet create --resource-group networkingdemoRG 
--name pvnvnet --address-prefixes 10.0.0.0/16 --location eastus
3. Crating a subnet --> az network vnet subnet create --resource-group networkingdemoRG 
--vnet-name pvnvnet --name Publicsubnet --address-prefixes 10.0.1.0/24
4. Same commands works in Powershell(best for windows ad/admins)
5. Cloud shell is browser based for ex, az account show, az resource list --resource-group networkingdemoRG

Managed Services
================
Storage
Database
Data Warehouse
Integration
Streaming
Visualisation
AI/ML

Storage
=======
PAAS
Managed cloud storage service --> High availability, durable, scalable & redundant storage.
Service to store files, messages, tables & any other types of information. 
Also used for VM's which includes disk and files.

1 subscription --> 100 accounts --> 1 account * 500 tb
durability --> 99.9999999999 (11) with replication
secured encryption, entra id integration, access controls
Cost effective --> pay as you use

3 categories
============
1. Storage for VM's (disks & files)
2. Unstructured data (blobs, datalake stores)
3. Structured data (Tables, SQL db, cosmos db)

Types of AZ storage
===================
1. Blobs --> Object storage --> Huge amount of unstructured data such as text, images, videos, data for back-up, 
archiving,disaster recovery, binary data
2. Files --> Highly available network file sharing over SMB (Server Message Block) --> Suitable for migration of 
the data
3. Tables --> Store structured data (SQL, NOSQL), key-value pair, schema less design
4. Queues --> Store & Retrieve Messages, each message of maximum size 64 kb --> Store millions of messages
5. Disk --> For VM disks, like your server's hard drive

Types of blob storages
======================
Block blobs --> Any text, files, videos, images etc. saved in blob storage are by default saves as block blobs (max size-->  5 pb)
Page blobs --> Random access files upto 8 tb --> virtual hard drive --> serves as a disk for VM's
Append blobs --> Made up of multiple block blobs, optimized for append operations --> 
ideal for log data analysis in VM

Performance / access tiers
==========================
Hot --> Optimized for storing data that is accessed frequently like VM, files, images, 
videos that are in regular use storage cost (high), read cost (low)

Cool --> Optimized for storing data that is infrequently accessed and stored for atleast 30 days 
like back-up data storage cost (low), read cost (higher than hot)

Cold (Archive) --> Optimized for storing data that is rarely accesses and stored for atleast 
180 days with flexible latency storage cost (least), read cost (highest)

Storage Replication
====================
Local Redundancy Storage --> 3 copies of data in 3 different storage boxes within same data center
Geo RS --> 3 copies of data in primary region, 3 copies in secondary region
Zone RS --> 3 copies of data in multiple data centers within same region
GZRS --> Same as ZRS, single physical location in secondary region
Read only GRS --> Same as GRS, Read only Access in secondary region
RA-ZRS --> Same as ZRS, Read only Access in secondary region

Performance
===========
Standard --> Backed by HDD (magnetic drives), Lowest cost per gb, best for applications that 
requires bulk storage, infrequent data access

Premium --> Backed by SSD (Solid State drives), offers low latency & consistant performance, 
use with Azure's VM disks, best for data , i/o intensive applications --> DB

General Purpose V1 --> Legacy, doesn't support any performancy tiers, standard and premium, (doesn't support ZRS, GZRS)
General Purpose V2 --> Performance tiers, all Replications, standard and premium
Blob storage --> Unstructured data, (append blobs, block blobs)

Blob Containers & categories
============================
Containers --> Directory structure, can store many blobs under one container

1. Creating storage account
2. Access the account from Explorer using access keys
3. Using SAS url for blob
4. Generating and using SAS url for Containers
5. Create alerts for ingress, egress in Monitor

# Access Keys --> are given if you would like to give account level access --> High risk
You can always rotate the keys to make older keys invalid
by default 2 access keys are given

# SAS --> Temporary, timed(validity), scoped(read only, write only, list, delete)

Make storage account as public then anonymous users can access with a url
Suppose your container is public but account is restricted to public, then can't access with url

# Access policy

Data lake GEN1 
Data lake GEN2 --> Big Data

Versioning

To upgrade blob storage to data lake gen 2 from CLI
admin>az storage account hns-migration start --type validation -n pvnstorage8 -g pvn-rg
admin>az storage account hns-migration start --type upgrade -n pvnstorage8 -g pvn-rg 
az storage account show --name pvnstorage8 --resource-group pvn-rg --query isHnsEnabled

life cycle management --> set up policies to decide the movement/lifecycle of the data

ADLS2
=====
Combines the best features of Data lake Analytics (Hadoop compatible, Optimized drivers) 
and Blob storage (Low cost, storage tiers, high availability)

Scalable, secured & managed data lake.
6 layers of protection for security & compliance

1. Network Security --> Firewalls, Private & Service endpoints
2. Authentication --> MFA, Service Principal, AAD
3. Authorisation --> RBAC, ACL's, POSIX
4. Data encryption --> SSE, CSE,  Key-vault, EKM
5. Data Access Controls --> Lifecycle management policies, retention policies, data expiration
6. Monitoring & auditing --> Az monitor, Log analytics

Features		Blob				ADLS Gen2
========		====				=========
Top level Organisation	Containers			Containers

Low level Organisation	Virtual directory		Directory

Data containers		Blobs				Files

Soft delete		Yes				Yes

Static Website		Yes				Yes

RBAC			Yes				Yes

Access Control Lists	No				Yes

SAS			Yes				Yes

Access Keys		Yes				Yes


ADLS2 is better than Blob storage in performance, security, scalability but costlier than blob storage
It stores a new version for each file modification. Can be accessed using version history, can do retrieval or deletion.

RDBMS
=====
ACID properties
Normalizations
Keys
ER-diagrams

CRUD operations
===============
DDL
DML
TCL

Projection of data --> SELECT
Concatenation --> |, quote operator
single row functions --> upper, lower, initcap, round
multi-row functions --> group functions(avg,sum, min, max, count)
Restricting records --> where
groupby --> having
joins --> inner join, outer joins, cross joins, self joins
subqueries

SELECT AVG(SALARY), DEPT
FROM EMP
WHERE SALARY>10000
GROUP BY(DEPT)
HAVING DEPT IN (60,70,80)


Azure SQL Database 
==================
General purpose RDBMS as a services (DBaaS) based on the Microsoft SQL server db engine.

Azure sql --> transaction based apps
Azure db for postgreSQL --> opensource for advanced querying --> handling geographical data in mapping apps
Azure db for mysql --> Liteweight and fast, ideal for web apps like forums, e commerce site on php

Benefits
========
Convenient, Cost effective, Scalable, Secure, SLA (99.99% uptime)

Microsoft --> hardware, Data centre, Virtualization, patching, OS, networking, Security, auditing, scaling, back-up/recovery
You --> Design, develop, migrations, capacity planning, performance tuning, automation, optimization  

V-core based purchasing model (Precise ctrl)--> choose the number of vcores, memory, speed, 
also utilise hybrid (integrate/use your existing sql server licenses) 

DTU based purchasing model --> blend of compute, memory, I/O resources in 3 service tiers to support light weight to heavy db workloads.
Compute size s within each tier provides a different mix of these resources.

Deployment models
=================
Single DB -- Isolated & portable , contained, own set of resources
Elastic pool --> Collection of single db's, shared set of resources, cost effective if the usage is unpredictable
Hyperscale --> For massive scale-up to to 100 tb, with fast back-up (every seconds)
Managed instances --> 100% compatible with latest ms sql server, lift and shift/migration

az sql server create --name ecommerceserver --resource-group --urrg --location eastus --admin-user dbadmin 
--admin-password Strongpwd@123

az sql db create --resource-group urrg --server ecommerceserver --name ecommdb --edition GeneralPurpose --family Gen5 --capacity 2 
--compute-model Serverless

Security
=========
Firewall rules
Az AD 
Encryption

MS sql server --> t-sql
Oracle --> pl/sql
postgre sql --> Opensource, xml/json complex types

Big Data --> Hadoop

Distributed storage
Distributed parallel processing 

1. Design a schema for a movie app using rdbms/nosql

NOSQL DB's --> No fixed schema
==========
1. Key-value pair --> Simplest nosql type --> a unique key pointing to values
	Simple look-ups, limited querying
	Quick read/writes, good for chaching or sessions
	Redis, Table API in cosmos

2. Document DB's --> Data is stored as self-contained docs usually in json
	Good for content management
	Mongo db, couch db, Mongodb API

3. Columnar DB's --> Organises data in tables with rows keys, group of columns
	Analytics, big data
	Cassandra, Hbase, Cassandra API

4. Graph DB's --> Stores data as nodes(vertices and edges), connections
	Neo4j, Gremlin API

CAP theorem
===========
Cosmos DB --> Changing consistancy, index optimization

{"id":"U1", "userid":"U1", "name":"Arun", "email":"arun@xyz.com", "signupdt":"2025-10-02"}
{"id":"U2", "userid":"U2", "name":"Kiran","preferences":["laptop","mouse"],"signupdt":"2025-10-07"}

SELECT c.name, c.preferences
from c
where array_contains(c.preferences, "laptop")

SELECT count(1) as usercount
from c 
where is_defined(c.preferences) 

SELECT c.name, c.signupdt
from c
where c.signupdt<="2025-10-05"

SELECT c.name, c.signupdt
from c
where c.signupdt<="2025-10-05" AND array_contains(c.preferences,"mouse")

Consistency
metrics --> 99 percentile replication latency
indexing policy
RBAC --> Assign roles --> read/write/contributor
Backup & restore --> periodic backup, continuous backup(point in time restore)
Cost optimization --> manual/auto scale
CORS --> security feature to allow webiste to talk with your apps/db
Performance tuning --> adjust indexing policy, adjust manul/autoscale ru, use partition key
TTL, Change feed

Azure Synapse Analytics --> Attached to ADLS2 account
=======================
Managed Enterprise Data warehousing and big data analytics solution on cloud

SQL (Synapse sql)
Spark (processing)
Pipelines (Integration) --> ETL, ELT (Az data factory)

Supports t-sql, python, scala, .net, java, R, Spark sql, KQL

Integrates well with other services such as Power BI, Cosmos DB, Azure ML etc.

Synapse workspace --> Managed resource group (all the components used will be created under this)
==================
To build cloud based enterprise analytical solution attached with ADLS gen2 file system

1. Dedicated SQL pools --> Predictable workloads
2. Serverless sql/Spark pools --> On-demand

SQL --> SQL pool --> run t-sql based script on data in linked services

Linked Service --> Connection String, defines the connection information for workspace to connect to an external source

Open Rowset --> Allows you to access files in Az storage and returns the content as a set of rows

Synapse sql
===========
Ability to do the t-sql based analytics in workspace
2 consumption models --> Serverless , Dedicated

Serverless sql pool --> built in --> Use sql without reserving any capacity
Billing is based on amount of data processed to run query.

Dedicated sql pool --> Consumes billable resources if it's active, pause the pool to reduce costs and this is associated with a sql db,
billing is based on per hour of reserved capacity --> pause the cluster

Data Explorer pool --> Used to run near real time analytics on large volumes of logs and time series data streaming from applications, 
websites, IoT devices, and more.

Spark for Synapse
==========--=----
Ability to do spark based analytics in Synapse workspace. Spark session is created when you choose spark pool
"POOL" is like a run time, it controls the resources used in the session.

Components --> Spark notebook, job definitions

Serverless Spark pool
=====================
External Table --> External data sources, File formats
Views --> Virtual tables
CETAS --> Create external table as select --> useful for exporting or transofrming data

Pipelines
=========
To move the data between services and orchestration activities.
Logical grouping of activities that performs a task together
Activities defines actions within pipelines --> Copying data, running a spark notebook or a sql query

Azure data factory
==================
Cloud based ETL for scheduling and managing workflows, orchestration and transformation of data at scale
Integration & data transformation

Linked services --> Connection strings, defines information needed for the data factory to connect with external resources

Datasets --> Represents the data structures within the data stores, which simply points to reference the data you want in your activities

Pipeline --> Logical grouping of activities that performs a unit of work

Activity --> Processing step in a pipeline

Data movement
Data transformation
Controlflow

Triggers --> Determines when a pipeline execution needs to be kicked off. 

Schedule trigger --> A trigger that involves a pipeline on a clock schedule
Tumbling window
Events

T-sql --> Transact sql --> Microsoft --> Azure sql database --> procedural programming
U-sql --> Big data analytics --> Az data lake analytics, az synapse --> scalable data processing

Dataflow --> Data transformation activity runs on a spark cluster, that allows the developer to perform graphical data transformation(joins, data cleaning, 
data manipulation)

Software Development Life Cycle
================================

1. Waterfall --> Sequential, linear

Scope of change is little
Good for simple, cost affective, well defined, limited time period projects

2. Agile

Iterations, project is delivered in iterations/sprints
Scope of change is likely
Allows to collect the feedback often from the clients, continuous improvement

Methodologies
=============
Scrum
Kanban
Lean

Benefits
========
Improved customer satisfaction, reduced project risk

Challenges
==========
Cultural shift, Scaling to larger teams, lack of clear requirements


3. Devops

Development + Operations

Culture --> Collaboration between Development & Operations team, they work as 1 team over here.

Phases --> CICD pipelines
=========================

Continous Development --> Version control --> Git, Bit bucket,sub version 

Continous Testing --> Selenium/ selenium grid --> Automation testing software, Opensource web driver 

Continous Integration --> Jenkins --> Opensource, 1000+ plugins

Continous Deployment --> Puppet, Chef, Ansible, Saltstack

Continous monitoring --> Splunk, Nagios, Grafana

Build tools --> Maven, Gradle, Ant

Tools
=====
Dockers --> Containers allows you to package your applications & its dependencies
Dockerhub --> Cloud based containarisation platform
Kubernetes --> Container management technology.

Puppet --> Operational tool, Define configurations for each & every host, scaaling up/down is dynamic

Nagios --> Continuous monitoring

Azure Devops
=============
Boards --> Used for tracking work (kanban, scrum, agile)
======
Epic
issues bugs
features
user story
artifacts --> allows teams to share packages such as Maven, npm, NuGet, 
and more from public and private sources and integrate package sharing into your pipelines

Repos --> To connect with your repository/manage source code
Pipelines --> To build CI/CD pipelines
Test plans --> Manual & exploratory testing, test case management/tracking defects, execution

Az    vs    AWS

blobs        s3
Cosmos db    Dynamo db
Synapse      Redshift
SQL          DBS
ADF          Pipelines
ML studio    Sagemaker
PowerBi      Athena, glue

git add .
git commit -m "saved"
git check out 

Security Center (Defender cloud)
================================
Assess resources --> Checks VMs, dbsm containers against security benchmark
Gives recommendations --> Suggests fixes like enable encryption, patching a software
Detect threats --> Spots suspicious activities (malware on a vm)

Alerts --> alarms that goes off when something's wrong

AZ Active Directory[Entra ID] --> Authentication, Single Sign-on, Application management, B2B, B2C, Device management, 
Multi-factor authentication, DDOS

1. Identity management --> User group and device management
2. Single Sign On (SSO) --> Access multiple applns  with one set of credentials
3. Multi-Factor Authentication --> Enhanced Security with additional verification steps
4. Directory integrations / conditional access

Azure Advanced Threat Protection (ATP) --> Portal for threat protection, identifying if there any compromises to the 
system

Governance --> Policy, RBAC, Resource locks (Cannot delete, Read only)
Tags --> Key-value pair

Monitor --> Collect, analyse and act on telemetry data from cloud and on-premise to improve performance

Health Centre --> Analyse, respond, visualise and integrate

Cost Management
Cost Analysis
Price Calculator
Budgets and Alerts
Advisor









